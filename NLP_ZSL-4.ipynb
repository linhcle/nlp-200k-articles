{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a860b1-e535-4a7d-8339-0e6f02cce418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (23.5.9)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.51.3)\n",
      "Collecting h5py>=2.9.0 (from tensorflow)\n",
      "  Using cached h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting keras<2.12,>=2.11.0 (from tensorflow)\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.12,>=2.11 (from tensorflow)\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.17.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: opt-einsum, keras, h5py, google-pasta, gast, astunparse, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The script markdown_py is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed astunparse-1.6.3 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 h5py-3.8.0 keras-2.11.0 markdown-3.4.3 opt-einsum-3.3.0 tensorboard-2.11.2 tensorflow-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f2add9-ff47-408c-a2ed-f65d2779bd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 06:05:02.474505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 06:05:04.975447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-19 06:05:04.975576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-19 06:05:04.975588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "debca209-8fa9-4764-883f-d57e853e17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2'\n",
    "file_name = 'NLP_data_v2.json'\n",
    "from google.cloud import storage\n",
    "import json\n",
    "\n",
    "# Instantiate a Google Cloud Storage client and specify required bucket and file\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "blob = bucket.blob(file_name)\n",
    "\n",
    "# Download the contents of the blob as a string and then parse it using json.loads() method\n",
    "data = json.loads(blob.download_as_string(client=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9eea3bc1-053c-48a6-acde-c3f9394c283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a44fa51-4332-499c-93e3-98c3728b937d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_13980/3292809502.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b7f7f6-0647-4466-af43-28a0271950d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 64\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d744bc-7266-4083-ba21-f7f5f67cb0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandarallel\n",
      "  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dill>=0.3.1 (from pandarallel)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1 in /opt/conda/lib/python3.7/site-packages (from pandarallel) (1.3.5)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from pandarallel) (5.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1->pandarallel) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1->pandarallel) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1->pandarallel) (1.16.0)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16677 sha256=30744734cefa3d9c49554cec4ac72a3398241db4f4b99f1c4e8372e564d9b63b\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/36/7d/02/fe609e415bbba9146afcc4a9171bf47a36c6b6ebd9c4b2cb6c\n",
      "Successfully built pandarallel\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: dill, pandarallel\n",
      "Successfully installed dill-0.3.6 pandarallel-1.6.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e44f22-96df-4bb2-ace9-5b34f9bc7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 63 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47f4f8-b2a7-4f12-ab7f-1ebe4c147ad8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. ZSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ebea02-d4f8-463c-a532-c44030705b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting ktrain\n",
      "  Downloading ktrain-0.37.0.tar.gz (25.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from ktrain) (3.5.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.3.5)\n",
      "Collecting fastprogress>=0.1.21 (from ktrain)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from ktrain) (2.28.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ktrain) (23.1)\n",
      "Collecting langdetect (from ktrain)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba (from ktrain)\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cchardet (from ktrain)\n",
      "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.7/263.7 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting chardet (from ktrain)\n",
      "  Downloading chardet-5.1.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting syntok>1.3.3 (from ktrain)\n",
      "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
      "Collecting tika (from ktrain)\n",
      "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers>=4.17.0 (from ktrain)\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from ktrain)\n",
      "  Downloading sentencepiece-0.1.99-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras_bert>=0.86.0 (from ktrain)\n",
      "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting whoosh (from ktrain)\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras_bert>=0.86.0->ktrain) (1.21.6)\n",
      "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
      "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.1->ktrain) (2023.3)\n",
      "Collecting regex>2016 (from syntok>1.3.3->ktrain)\n",
      "  Downloading regex-2023.5.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (756 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.6/756.6 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (3.12.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.17.0->ktrain)\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.17.0->ktrain)\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (4.11.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect->ktrain) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (2022.12.7)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->ktrain) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->ktrain) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tika->ktrain) (67.7.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.17.0->ktrain) (3.15.0)\n",
      "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, jieba, langdetect, tika\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.37.0-py3-none-any.whl size=25320561 sha256=cbabfdb54ebf4a9b920d0f92b9d310261c73d74d31753384d3ac6a39ae79f311\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/cc/dd/58/2be97f292a25210932990d69cadee7bcebcdccfd49e0d58bde\n",
      "  Building wheel for keras_bert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33501 sha256=4a7d7280d67af25f4575f3d242ea39f37bce51d0f1d02c27e8c42ec8de789345\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/a4/e8/45/842b3a39831261aef9154b907eacbc4ac99499a99ae829b06f\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12287 sha256=4dd573647e43cc8fe3035e1d795453f228be83a705b7bf1f1c646389c47c2204\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/46/68/26/692ed21edd832833c3b0a0e21615bcacd99ca458b3f9ed571f\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3943 sha256=507db44a3b3b14b35f527a809b7e6e8e808beb1b94a8bba06d71ee1321bbeac0\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/81/67/b5/d847588d075895281e1cf5590f819bd4cf076a554872268bd5\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4653 sha256=a95ca74e1f02577c916199a63f6c22593d172f000d7b24b91cda760e4b2fd772\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/85/5d/1c/2e619f594f69fbcf8bc20943b27d414871c409be053994813e\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14979 sha256=4a1a4c3bba72e2bfe88e8ac57d0d953764c832a048a84d003da1e35aea282f80\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/86/aa/3c/9d15d24005179dae08ff291ce99c754b296347817d076fd9fb\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=15e40c77522246432799571bc25e7f4d9cad740c99f87dd27da8fc455d227b65\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/8d/c1/a0/dc44fcf68c857b7ff6be9a97e675e5adf51022eff1169b042f\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4968 sha256=a6c696ec36b02e068b9263c33c3dbe61a56f84440ddddb81c080b935775e4e47\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/c2/75/6f/d42f6e051506f442daeba53ff1e2d21a5f20ef8c411610f2bb\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=d3657494da067ab521a6186f828700c2ac586eb11d7a8c041ebd739ddddce4ae\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=05ba717c9438fcb3c10e5f5bc7e9b48ae37d3ca20e32523a99a614765f184cb4\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/24/aa/17/5bc7c72e9a37990a9620cc3aad0acad1564dcff6dbc2359de3\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=81319d8cf149bbe54b3dfd866226acd549f7e56ac1de7a24b580b7e8db14058b\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
      "  Building wheel for tika (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32625 sha256=3a3e27a62bf61b35ce7db4741dc1c5b405a6969b96bdb0572e526b1dc18dcf30\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/d0/e8/f2/4d6ee3cf46b79e22dcc7d4cdcbeed804c985d346b44a213672\n",
      "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention jieba langdetect tika\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: whoosh, tokenizers, sentencepiece, jieba, cchardet, regex, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, fastprogress, chardet, tika, syntok, keras-multi-head, huggingface-hub, transformers, keras-transformer, keras_bert, ktrain\n",
      "Successfully installed cchardet-2.1.7 chardet-5.1.0 fastprogress-1.0.3 huggingface-hub-0.14.1 jieba-0.42.1 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.37.0 langdetect-1.0.9 regex-2023.5.5 sentencepiece-0.1.99 syntok-1.4.4 tika-2.6.0 tokenizers-0.13.3 transformers-4.29.2 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "874522e4-872a-48f3-a61e-afb8fdfcd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c527a4e-dedc-438d-8e8c-974390d3fad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc51a22a44bc468f98a86860b3b3d9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b48b02901ac4515bb6a4367ccaa6543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5be00bfbdc424f9c888925b4d346fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9ada043d744d68a27b39dcb34db1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2212a58658a54faba644eb65465baacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca9844b665d4ea6ad99078c7ac43173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zsl = ktrain.text.ZeroShotClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b1fa2963-3f43-472c-b5e7-7721ebf99309",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''My husband ordered a fruit arrangement for me for Valentine's Day. \n",
    "He had planned on taking me to the movies with two free tickets he was promised with a \n",
    "promotion you had been advertising. My husband was unaware that these tickets came via email. \n",
    "However, your sales representative who took his order failed to record his email address. \n",
    "Therefore we never received the tickets. \n",
    "I have called corporate and the store manager about this. \n",
    "They seem to not be able to resolve things in a timely manner. \n",
    "Also the fruit was not the best tasting. \n",
    "Needless to say we will never be supporting your business again. \n",
    "Overall poor customer service and a very overpriced product.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d314a23a-631b-4ba7-9b69-372750be0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = zsl.predict(text, labels=['negative', 'positive'], include_labels=True,\n",
    "#             nli_template=\"The sentiment of this restaurant review is {}.\",multilabel=False)\n",
    "# max_tuple = max(res, key=lambda x: x[1])\n",
    "# print(max_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d61db63-0919-4a9c-898b-f9683c1bb92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 52s, sys: 358 ms, total: 20min 52s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiments = []\n",
    "for text in df_sample['clean_text']:\n",
    "    res = zsl.predict(text, labels=['negative', 'positive'], \n",
    "                      include_labels=True, \n",
    "                      nli_template=\"The sentiment of this text is {}.\", \n",
    "                      multilabel=False, batch_size = 64)\n",
    "    max_tuple = max(res, key=lambda x: x[1])\n",
    "    sentiments.append(max_tuple[0])\n",
    "\n",
    "df_sample['sentiment'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192e1cc8-890b-44d3-9369-704103e8e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "# df_sample[['clean_text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff715fc-41d0-4c8c-a89c-369393f8b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "28d880e4-2277-4bf1-af60-b560f44c7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_eng = df_sample[['clean_text']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aaa28a0-b841-4356-a180-bb7313ef341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['fraud', 'healthcare', 'robotic', 'finance', 'fake', 'bot', 'entertainment', 'generative', 'blockchain', 'hardware', 'security', 'journalism', 'legal','administrative','life science','social science','sales','farming','education','food','transportation','production','construction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f6ab76-0039-4c28-a7f0-e26ff640fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18d 16h 18min 38s, sys: 3h 59min 42s, total: 18d 20h 18min 20s\n",
      "Wall time: 14h 9min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "predictions = zsl.predict(texts, labels=labels, include_labels=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09f90dcc-0c7f-4f90-b720-6ea875d0571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns=[labels])\n",
    "\n",
    "# news_topics.columns = [['text'] + labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8430f60f-78d0-4a90-b232-99de26aef676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>robotic</th>\n",
       "      <th>finance</th>\n",
       "      <th>fake</th>\n",
       "      <th>bot</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>generative</th>\n",
       "      <th>blockchain</th>\n",
       "      <th>hardware</th>\n",
       "      <th>...</th>\n",
       "      <th>administrative</th>\n",
       "      <th>life science</th>\n",
       "      <th>social science</th>\n",
       "      <th>sales</th>\n",
       "      <th>farming</th>\n",
       "      <th>education</th>\n",
       "      <th>food</th>\n",
       "      <th>transportation</th>\n",
       "      <th>production</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(fraud, 0.00012895461986772716)</td>\n",
       "      <td>(healthcare, 0.0001743163011269644)</td>\n",
       "      <td>(robotic, 0.3031499683856964)</td>\n",
       "      <td>(finance, 0.0011801995569840074)</td>\n",
       "      <td>(fake, 0.004023555666208267)</td>\n",
       "      <td>(bot, 0.877078652381897)</td>\n",
       "      <td>(entertainment, 0.0015653471928089857)</td>\n",
       "      <td>(generative, 0.35918983817100525)</td>\n",
       "      <td>(blockchain, 0.00039664204814471304)</td>\n",
       "      <td>(hardware, 0.002197129186242819)</td>\n",
       "      <td>...</td>\n",
       "      <td>(administrative, 0.011698845773935318)</td>\n",
       "      <td>(life science, 0.0007523724343627691)</td>\n",
       "      <td>(social science, 0.1413007229566574)</td>\n",
       "      <td>(sales, 0.000692297238856554)</td>\n",
       "      <td>(farming, 9.927610517479479e-05)</td>\n",
       "      <td>(education, 0.00017354870215058327)</td>\n",
       "      <td>(food, 8.568831253796816e-05)</td>\n",
       "      <td>(transportation, 0.9902223348617554)</td>\n",
       "      <td>(production, 0.03698590397834778)</td>\n",
       "      <td>(construction, 0.0009491058299317956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(fraud, 0.0004908709088340402)</td>\n",
       "      <td>(healthcare, 0.22053837776184082)</td>\n",
       "      <td>(robotic, 0.813249945640564)</td>\n",
       "      <td>(finance, 0.0006573498831130564)</td>\n",
       "      <td>(fake, 0.007770445663481951)</td>\n",
       "      <td>(bot, 0.8594974279403687)</td>\n",
       "      <td>(entertainment, 0.028624221682548523)</td>\n",
       "      <td>(generative, 0.2235848754644394)</td>\n",
       "      <td>(blockchain, 0.0021368651650846004)</td>\n",
       "      <td>(hardware, 0.004519166424870491)</td>\n",
       "      <td>...</td>\n",
       "      <td>(administrative, 0.0011984918965026736)</td>\n",
       "      <td>(life science, 0.007798329461365938)</td>\n",
       "      <td>(social science, 0.5732425451278687)</td>\n",
       "      <td>(sales, 0.0005590548971667886)</td>\n",
       "      <td>(farming, 0.0002821839298121631)</td>\n",
       "      <td>(education, 0.6706202030181885)</td>\n",
       "      <td>(food, 0.0003329007013235241)</td>\n",
       "      <td>(transportation, 0.001760217361152172)</td>\n",
       "      <td>(production, 0.02440587431192398)</td>\n",
       "      <td>(construction, 0.0019186113495379686)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fraud                           healthcare  \\\n",
       "0  (fraud, 0.00012895461986772716)  (healthcare, 0.0001743163011269644)   \n",
       "1   (fraud, 0.0004908709088340402)    (healthcare, 0.22053837776184082)   \n",
       "\n",
       "                         robotic                           finance  \\\n",
       "0  (robotic, 0.3031499683856964)  (finance, 0.0011801995569840074)   \n",
       "1   (robotic, 0.813249945640564)  (finance, 0.0006573498831130564)   \n",
       "\n",
       "                           fake                        bot  \\\n",
       "0  (fake, 0.004023555666208267)   (bot, 0.877078652381897)   \n",
       "1  (fake, 0.007770445663481951)  (bot, 0.8594974279403687)   \n",
       "\n",
       "                            entertainment                         generative  \\\n",
       "0  (entertainment, 0.0015653471928089857)  (generative, 0.35918983817100525)   \n",
       "1   (entertainment, 0.028624221682548523)   (generative, 0.2235848754644394)   \n",
       "\n",
       "                             blockchain                          hardware  \\\n",
       "0  (blockchain, 0.00039664204814471304)  (hardware, 0.002197129186242819)   \n",
       "1   (blockchain, 0.0021368651650846004)  (hardware, 0.004519166424870491)   \n",
       "\n",
       "   ...                           administrative  \\\n",
       "0  ...   (administrative, 0.011698845773935318)   \n",
       "1  ...  (administrative, 0.0011984918965026736)   \n",
       "\n",
       "                            life science  \\\n",
       "0  (life science, 0.0007523724343627691)   \n",
       "1   (life science, 0.007798329461365938)   \n",
       "\n",
       "                         social science                           sales  \\\n",
       "0  (social science, 0.1413007229566574)   (sales, 0.000692297238856554)   \n",
       "1  (social science, 0.5732425451278687)  (sales, 0.0005590548971667886)   \n",
       "\n",
       "                            farming                            education  \\\n",
       "0  (farming, 9.927610517479479e-05)  (education, 0.00017354870215058327)   \n",
       "1  (farming, 0.0002821839298121631)      (education, 0.6706202030181885)   \n",
       "\n",
       "                            food                          transportation  \\\n",
       "0  (food, 8.568831253796816e-05)    (transportation, 0.9902223348617554)   \n",
       "1  (food, 0.0003329007013235241)  (transportation, 0.001760217361152172)   \n",
       "\n",
       "                          production                           construction  \n",
       "0  (production, 0.03698590397834778)  (construction, 0.0009491058299317956)  \n",
       "1  (production, 0.02440587431192398)  (construction, 0.0019186113495379686)  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2db75f8b-454b-47a2-86d4-ef6f0f641cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0d91a6a-6ed6-4ae6-b904-7318d5bdd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.columns = predictions_df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a880ce2-6693-49c5-822f-5efc4dd908ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>robotic</th>\n",
       "      <th>finance</th>\n",
       "      <th>fake</th>\n",
       "      <th>bot</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>generative</th>\n",
       "      <th>blockchain</th>\n",
       "      <th>hardware</th>\n",
       "      <th>...</th>\n",
       "      <th>administrative</th>\n",
       "      <th>life science</th>\n",
       "      <th>social science</th>\n",
       "      <th>sales</th>\n",
       "      <th>farming</th>\n",
       "      <th>education</th>\n",
       "      <th>food</th>\n",
       "      <th>transportation</th>\n",
       "      <th>production</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(fraud, 0.00012895461986772716)</td>\n",
       "      <td>(healthcare, 0.0001743163011269644)</td>\n",
       "      <td>(robotic, 0.3031499683856964)</td>\n",
       "      <td>(finance, 0.0011801995569840074)</td>\n",
       "      <td>(fake, 0.004023555666208267)</td>\n",
       "      <td>(bot, 0.877078652381897)</td>\n",
       "      <td>(entertainment, 0.0015653471928089857)</td>\n",
       "      <td>(generative, 0.35918983817100525)</td>\n",
       "      <td>(blockchain, 0.00039664204814471304)</td>\n",
       "      <td>(hardware, 0.002197129186242819)</td>\n",
       "      <td>...</td>\n",
       "      <td>(administrative, 0.011698845773935318)</td>\n",
       "      <td>(life science, 0.0007523724343627691)</td>\n",
       "      <td>(social science, 0.1413007229566574)</td>\n",
       "      <td>(sales, 0.000692297238856554)</td>\n",
       "      <td>(farming, 9.927610517479479e-05)</td>\n",
       "      <td>(education, 0.00017354870215058327)</td>\n",
       "      <td>(food, 8.568831253796816e-05)</td>\n",
       "      <td>(transportation, 0.9902223348617554)</td>\n",
       "      <td>(production, 0.03698590397834778)</td>\n",
       "      <td>(construction, 0.0009491058299317956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(fraud, 0.0004908709088340402)</td>\n",
       "      <td>(healthcare, 0.22053837776184082)</td>\n",
       "      <td>(robotic, 0.813249945640564)</td>\n",
       "      <td>(finance, 0.0006573498831130564)</td>\n",
       "      <td>(fake, 0.007770445663481951)</td>\n",
       "      <td>(bot, 0.8594974279403687)</td>\n",
       "      <td>(entertainment, 0.028624221682548523)</td>\n",
       "      <td>(generative, 0.2235848754644394)</td>\n",
       "      <td>(blockchain, 0.0021368651650846004)</td>\n",
       "      <td>(hardware, 0.004519166424870491)</td>\n",
       "      <td>...</td>\n",
       "      <td>(administrative, 0.0011984918965026736)</td>\n",
       "      <td>(life science, 0.007798329461365938)</td>\n",
       "      <td>(social science, 0.5732425451278687)</td>\n",
       "      <td>(sales, 0.0005590548971667886)</td>\n",
       "      <td>(farming, 0.0002821839298121631)</td>\n",
       "      <td>(education, 0.6706202030181885)</td>\n",
       "      <td>(food, 0.0003329007013235241)</td>\n",
       "      <td>(transportation, 0.001760217361152172)</td>\n",
       "      <td>(production, 0.02440587431192398)</td>\n",
       "      <td>(construction, 0.0019186113495379686)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fraud                           healthcare  \\\n",
       "0  (fraud, 0.00012895461986772716)  (healthcare, 0.0001743163011269644)   \n",
       "1   (fraud, 0.0004908709088340402)    (healthcare, 0.22053837776184082)   \n",
       "\n",
       "                         robotic                           finance  \\\n",
       "0  (robotic, 0.3031499683856964)  (finance, 0.0011801995569840074)   \n",
       "1   (robotic, 0.813249945640564)  (finance, 0.0006573498831130564)   \n",
       "\n",
       "                           fake                        bot  \\\n",
       "0  (fake, 0.004023555666208267)   (bot, 0.877078652381897)   \n",
       "1  (fake, 0.007770445663481951)  (bot, 0.8594974279403687)   \n",
       "\n",
       "                            entertainment                         generative  \\\n",
       "0  (entertainment, 0.0015653471928089857)  (generative, 0.35918983817100525)   \n",
       "1   (entertainment, 0.028624221682548523)   (generative, 0.2235848754644394)   \n",
       "\n",
       "                             blockchain                          hardware  \\\n",
       "0  (blockchain, 0.00039664204814471304)  (hardware, 0.002197129186242819)   \n",
       "1   (blockchain, 0.0021368651650846004)  (hardware, 0.004519166424870491)   \n",
       "\n",
       "   ...                           administrative  \\\n",
       "0  ...   (administrative, 0.011698845773935318)   \n",
       "1  ...  (administrative, 0.0011984918965026736)   \n",
       "\n",
       "                            life science  \\\n",
       "0  (life science, 0.0007523724343627691)   \n",
       "1   (life science, 0.007798329461365938)   \n",
       "\n",
       "                         social science                           sales  \\\n",
       "0  (social science, 0.1413007229566574)   (sales, 0.000692297238856554)   \n",
       "1  (social science, 0.5732425451278687)  (sales, 0.0005590548971667886)   \n",
       "\n",
       "                            farming                            education  \\\n",
       "0  (farming, 9.927610517479479e-05)  (education, 0.00017354870215058327)   \n",
       "1  (farming, 0.0002821839298121631)      (education, 0.6706202030181885)   \n",
       "\n",
       "                            food                          transportation  \\\n",
       "0  (food, 8.568831253796816e-05)    (transportation, 0.9902223348617554)   \n",
       "1  (food, 0.0003329007013235241)  (transportation, 0.001760217361152172)   \n",
       "\n",
       "                          production                           construction  \n",
       "0  (production, 0.03698590397834778)  (construction, 0.0009491058299317956)  \n",
       "1  (production, 0.02440587431192398)  (construction, 0.0019186113495379686)  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7335091-feb9-48bf-8622-d8f197d20554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>robotic</th>\n",
       "      <th>finance</th>\n",
       "      <th>fake</th>\n",
       "      <th>bot</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>generative</th>\n",
       "      <th>blockchain</th>\n",
       "      <th>hardware</th>\n",
       "      <th>...</th>\n",
       "      <th>administrative</th>\n",
       "      <th>life science</th>\n",
       "      <th>social science</th>\n",
       "      <th>sales</th>\n",
       "      <th>farming</th>\n",
       "      <th>education</th>\n",
       "      <th>food</th>\n",
       "      <th>transportation</th>\n",
       "      <th>production</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.30315</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.877079</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.359190</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.141301</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.990222</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.220538</td>\n",
       "      <td>0.81325</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.859497</td>\n",
       "      <td>0.028624</td>\n",
       "      <td>0.223585</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.573243</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.670620</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.001919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fraud  healthcare  robotic   finance      fake       bot  entertainment  \\\n",
       "0  0.000129    0.000174  0.30315  0.001180  0.004024  0.877079       0.001565   \n",
       "1  0.000491    0.220538  0.81325  0.000657  0.007770  0.859497       0.028624   \n",
       "\n",
       "   generative  blockchain  hardware  ...  administrative  life science  \\\n",
       "0    0.359190    0.000397  0.002197  ...        0.011699      0.000752   \n",
       "1    0.223585    0.002137  0.004519  ...        0.001198      0.007798   \n",
       "\n",
       "   social science     sales   farming  education      food  transportation  \\\n",
       "0        0.141301  0.000692  0.000099   0.000174  0.000086        0.990222   \n",
       "1        0.573243  0.000559  0.000282   0.670620  0.000333        0.001760   \n",
       "\n",
       "   production  construction  \n",
       "0    0.036986      0.000949  \n",
       "1    0.024406      0.001919  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = predictions_df.applymap(lambda x: x[1])\n",
    "predictions_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59dd70cd-074a-4b95-9d57-96df58f614c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_topics = df.join(predictions_df, how='inner')\n",
    "news_topics = news_topics.drop(columns = ['index','language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f92db422-0fc7-4ec9-80bf-29d8dc8f1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_topics.to_csv('df_with_topic_labels.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19680888-a976-4785-9c78-bdddf1e8a7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Copying file://topic_labels.csv [Content-Type=text/csv]...\n",
      "\\ [1 files][128.5 MiB/128.5 MiB]                                                \n",
      "Operation completed over 1 objects/128.5 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp topic_labels.csv gs://cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e875a1d0-b869-4220-b840-65f233fe16e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Copying file://df_with_topic_labels.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "| [1 files][  2.2 GiB/  2.2 GiB]   20.3 MiB/s                                   \n",
      "Operation completed over 1 objects/2.2 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp df_with_topic_labels.csv gs://cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6676b6a9-d0d1-469d-a504-cf200a5df35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df\n",
    "predictions_df.to_csv('prediction_df.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e7ebe2c9-44e5-4369-8b05-96d82c53c5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Copying file://prediction_df.csv [Content-Type=text/csv]...\n",
      "- [1 files][ 73.4 MiB/ 73.4 MiB]                                                \n",
      "Operation completed over 1 objects/73.4 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp prediction_df.csv gs://cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da70ff41-4d37-4f0c-81f1-3073331fd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['topic'] = predictions_df.apply(lambda row: row.idxmax(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eab1e366-1434-4e25-9387-4f28aab20a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = predictions_df.topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5ab2490-65c8-4bc6-810c-38e0ae076165",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_topics_2 = df.join(labels, how='inner')\n",
    "news_topics_2 = news_topics_2.drop(columns = ['index','language','text','clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c723d5f4-6c66-436b-b118-4f1505043b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://en.people.cn/n3/2021/0318/c90000-9830122.html</td>\n",
       "      <td>1616025600000</td>\n",
       "      <td>Artificial intelligence improves parking efficiency in Chinese cities - People's Daily Online</td>\n",
       "      <td>transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://newsparliament.com/2020/02/27/children-with-autism-saw-their-learning-and-social-skills-boosted-after-playing-with-this-ai-robot/</td>\n",
       "      <td>1582761600000</td>\n",
       "      <td>Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot – News Parliament</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        url  \\\n",
       "0                                                                                      http://en.people.cn/n3/2021/0318/c90000-9830122.html   \n",
       "1  http://newsparliament.com/2020/02/27/children-with-autism-saw-their-learning-and-social-skills-boosted-after-playing-with-this-ai-robot/   \n",
       "\n",
       "            date  \\\n",
       "0  1616025600000   \n",
       "1  1582761600000   \n",
       "\n",
       "                                                                                                                  title  \\\n",
       "0                         Artificial intelligence improves parking efficiency in Chinese cities - People's Daily Online   \n",
       "1  Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot – News Parliament   \n",
       "\n",
       "            topic  \n",
       "0  transportation  \n",
       "1             bot  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_topics_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "44134545-6646-4f7b-8f10-cf8e42cd841c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153517, 4)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_topics_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "978763e3-a817-4e05-8b3c-76926c06b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_topics_2.to_csv('df_with_max_topic_labels.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "959a9426-bacf-4b90-8bd1-95b6e8f6fec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Copying file://df_with_max_topic_labels.csv [Content-Type=text/csv]...\n",
      "\\ [1 files][ 37.8 MiB/ 37.8 MiB]                                                \n",
      "Operation completed over 1 objects/37.8 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp df_with_max_topic_labels.csv gs://cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb1bdc-5e53-405d-979c-eb106ab45ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8161b321-9a59-43a4-b47f-4ea806448eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from google.cloud import storage\n",
    "\n",
    "# # Specify the Google Cloud Storage bucket and file details\n",
    "# bucket_name = 'cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2'\n",
    "# file_name = 'sentiment_labels.csv'\n",
    "\n",
    "# sentiment_labels = pd.read_csv('gs://cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2/sentiment_labels.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15bf32e0-7827-4157-a661-782cdb0f66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('gs://cloud-ai-platform-2e11e97a-0212-426c-b0fa-b1f124dd9ef2/entities_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6e7dd-e75b-4f40-b8e2-9b11cfee02f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4fbba264-1322-4b3f-b92a-5c739a679c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10846188, 4)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8263d-f41d-4ab4-87f6-1da5353f8f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
